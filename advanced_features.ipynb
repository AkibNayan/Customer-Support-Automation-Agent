{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "356a63d9",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Advanced Features for AI Agent Automation\n",
    "Including memory, tool integration, and multi-agent collaboration\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2075be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.tools import tool\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6132c272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "451cfe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ENHANCED STATE WITH MEMORY\n",
    "# ============================================================================\n",
    "class EnhancedAgentState(TypedDict):\n",
    "    \"\"\"Enhanced state with conversation history and memory.\"\"\"\n",
    "    query: str\n",
    "    conversation_history: List[Dict[str, str]]\n",
    "    category: str\n",
    "    retrieved_data: str\n",
    "    response: str\n",
    "    quality_score: int\n",
    "    timestamp: str\n",
    "    metadata: Dict[str, Any]\n",
    "    user_context: Dict[str, Any]    # User preferences, where key is str and value is Any\n",
    "    tools_used: List[str]\n",
    "    multi_agent_results: Dict[str, Any]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "712bbd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MEMORY MANAGEMENT\n",
    "# ============================================================================\n",
    "class ConversationMemory:\n",
    "    \"\"\"Manages conversation history and context\"\"\"\n",
    "    def __init__(self, max_history: int = 10):\n",
    "        self.max_history = max_history\n",
    "        self.conversations: Dict[str, List[Dict]] = {}\n",
    "    \n",
    "    def add_message(self, user_id: str, role: str, content: str):\n",
    "        \"\"\"Add messages to the conversation history\"\"\"\n",
    "        if user_id not in self.conversations:\n",
    "            self.conversations[user_id] = []\n",
    "        \n",
    "        self.conversations[user_id].append({\n",
    "            \"role\": role,\n",
    "            \"content\": content,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        # Keep only the recent history\n",
    "        if len(self.conversations[user_id]) > self.max_history:\n",
    "            self.conversations[user_id] = self.conversations[user_id][-self.max_history:]\n",
    "        \n",
    "    def get_history(self, user_id: str) -> List[Dict]:\n",
    "        \"\"\"Get the conversation history for a user\"\"\"\n",
    "        return self.conversations.get(user_id, [])\n",
    "    \n",
    "    def clear_history(self, user_id: str):\n",
    "        \"\"\"Clear the conversation history for a user\"\"\"\n",
    "        if user_id in self.conversations:\n",
    "            del self.conversations[user_id]\n",
    "            \n",
    "# Global Memory Instance\n",
    "memory = ConversationMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97955ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CUSTOM TOOLS\n",
    "# ============================================================================\n",
    "@tool\n",
    "def search_order_database(order_id: str) -> str:\n",
    "    \"\"\"Search the order database for order information\"\"\"\n",
    "    # Simulate the database lookup\n",
    "    mock_orders = {\n",
    "        \"12345\": {\n",
    "            \"status\": \"In Transit\",\n",
    "            \"expected_delivery\": \"2024-12-15\",\n",
    "            \"tracking_number\": \"TRK123456789\"\n",
    "        },\n",
    "        \"67890\": {\n",
    "            \"status\": \"Delivered\",\n",
    "            \"expected_delivery\": \"2024-12-10\",\n",
    "            \"tracking_number\": \"TRK987654321\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    order_info = mock_orders.get(order_id, None)\n",
    "    if order_info:\n",
    "        return json.dumps(order_info)\n",
    "    return json.dumps({\"error\": \"Order not found\"})\n",
    "\n",
    "@tool\n",
    "def check_inventory(product_id: str) -> str:\n",
    "    \"\"\"Check product inventory levels\"\"\"\n",
    "    # Simulate the inventory check\n",
    "    mock_inventory = {\n",
    "        \"PROD001\": {\n",
    "            \"in_stock\": True,\n",
    "            \"quantity\": 150\n",
    "        },\n",
    "        \"PROD002\": {\n",
    "            \"in_stock\": False,\n",
    "            \"quantity\": 0\n",
    "        },\n",
    "        \"PROD003\": {\n",
    "            \"in_stock\": True,\n",
    "            \"quantity\": 45\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    inventory = mock_inventory.get(product_id, {\"in_stock\": False, \"quantity\": 0})\n",
    "    # returns a JSON string\n",
    "    return json.dumps(inventory)\n",
    "    \n",
    "@tool\n",
    "def calculate_refund(order_id: str, return_reason: str) -> str:\n",
    "    \"\"\"Calculate refund amount based on order_id and return_reason\"\"\"\n",
    "    # Simulate refund calculation\n",
    "    refund_rules = {\n",
    "        \"defective\": 1.0,   # 100% refund\n",
    "        \"wrong_item\": 1.0,\n",
    "        \"not_satisfied\": 0.8,   # 80% refund restocking fee\n",
    "        \"change_mind\": 0.7\n",
    "    }\n",
    "    \n",
    "    refund_percentage = refund_rules.get(return_reason.lower(), 0.7)\n",
    "    estimated_amount = 99.99    # Mock order amount\n",
    "    refund_amount = estimated_amount * refund_percentage\n",
    "    \n",
    "    return json.dumps({\n",
    "        \"refund_amount\": round(refund_amount, 2),\n",
    "        \"refund_percentage\": refund_percentage * 100,\n",
    "        \"processing_time\": \"5-7 business days\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bf7253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TOOL EXECUTOR NODE\n",
    "# ============================================================================\n",
    "def tool_executor_node(state: EnhancedAgentState) -> EnhancedAgentState:\n",
    "    \"\"\"Execute appropriate tools based on query category\"\"\"\n",
    "    category = state.get('category', '')\n",
    "    query = state.get('query', '')\n",
    "    tools_used = []\n",
    "    tool_results = {}\n",
    "    \n",
    "    # Determine which tools to use\n",
    "    if category == 'ORDER_STATUS' and '#' in query:\n",
    "        # Extract the order id\n",
    "        order_id = query.split(\"#\")[-1].split()[0]\n",
    "        result = search_order_database.invoke({\"order_id\": order_id})\n",
    "        \n",
    "        tool_results['order_info'] = result\n",
    "        tools_used.append('search_order_database')\n",
    "    \n",
    "    elif category == 'REFUND' and '#' in query:\n",
    "        # Extract the order id\n",
    "        #order_id = query.split(\"#\")[-1].split()[0]\n",
    "        #Mock order id extraction\n",
    "        order_id = \"12345\"\n",
    "        result = calculate_refund.invoke({\n",
    "            \"order_id\": order_id,\n",
    "            \"return_reason\": \"defective\"\n",
    "        })\n",
    "        tool_results['refund_info'] = result\n",
    "        tools_used.append('calculate_refund')\n",
    "        \n",
    "    # Add tool results to the retrieved data \n",
    "    enhanced_data = state.get('retrieved_data', '')\n",
    "    \n",
    "    if tool_results:\n",
    "        enhanced_data += f\"\\n\\nTools Results: {json.dump(tool_results, indent=2)}\"\n",
    "        \n",
    "    return {\n",
    "        **state, \n",
    "        \"retrieved_data\": enhanced_data,\n",
    "        \"tools_used\": tools_used,\n",
    "        \"metadata\": {\n",
    "            **state.get(\"metadata\", {}),\n",
    "            \"tools_executed\": tools_used\n",
    "        }\n",
    "    }\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19976deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MULTI-AGENT COLLABORATION\n",
    "# ============================================================================\n",
    "class SpecializedAgent:\n",
    "    \"\"\"Base class for specialized agents\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, expertise: str):\n",
    "        self.name = name\n",
    "        self.expertise = expertise\n",
    "        self.llm = ChatGroq(\n",
    "            model=\"llama-3.3-70b-versatile\",\n",
    "            temperature=0.7,\n",
    "            groq_api_key=os.getenv(\"GROQ_API_KEY\", \"\")\n",
    "        )\n",
    "        \n",
    "    def process(self, query: str, context: str) -> str:\n",
    "        \"\"\"Process query with specialized knowledge\"\"\"\n",
    "        prompt = f\"\"\"You are a {self.expertise} specialist.\n",
    "        \n",
    "        Context: {context}\n",
    "        Query: {query}\n",
    "        \n",
    "        Provide a specialized response based on your expertise.\"\"\"\n",
    "        \n",
    "        messages = HumanMessage(content=prompt)\n",
    "        response = self.llm.invoke(messages)\n",
    "        \n",
    "        return response.content\n",
    "    \n",
    "class TechnicalSupportAgent(SpecializedAgent):\n",
    "    \"\"\"Agent specialized in technical support\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"TechSupport\", \"technical support and troubleshooting\")\n",
    "\n",
    "class RefundSpecialistAgent(SpecializedAgent):\n",
    "    \"\"\"Agent specialized in refunds and returns\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"RefundSpecialist\", \"refund processing and return\")\n",
    "    \n",
    "class OrderManagementAgent(SpecializedAgent):\n",
    "    \"\"\"Agent specialized in order management\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"OrderManagement\", \"order tracking and logistics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0576081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MULTI-AGENT COORDINATOR\n",
    "# ============================================================================\n",
    "def multi_agent_coordinator_node(state: EnhancedAgentState) -> EnhancedAgentState:\n",
    "    \"\"\"Coordinate multiple specialized agents\"\"\"\n",
    "    category = state.get(\"category\", \"\")\n",
    "    query = state.get(\"query\", \"\")\n",
    "    context = state.get(\"retrieved_data\", \"\")\n",
    "    \n",
    "    #Select appropriate specialized agent\n",
    "    specialized_response = None\n",
    "    agent_name = None\n",
    "    \n",
    "    if category == \"TECHNICAL_SUPPORT\":\n",
    "        agent = TechnicalSupportAgent()\n",
    "        specialized_response = agent.process(query, context)\n",
    "        agent_name = agent.name\n",
    "    \n",
    "    elif category == \"REFUND\":\n",
    "        agent = RefundSpecialistAgent()\n",
    "        specialized_response = agent.process(query, context)\n",
    "        agent_name = agent.name\n",
    "    \n",
    "    elif category == \"ORDER_MANAGEMENT\":\n",
    "        agent = OrderManagementAgent()\n",
    "        specialized_response = agent.process(query, context)\n",
    "        agent_name = agent.name\n",
    "    \n",
    "    multi_agent_results = {\n",
    "        \"agent_used\": agent_name,\n",
    "        \"specialized_response\": specialized_response\n",
    "    }\n",
    "    \n",
    "    #Use specialized response if available\n",
    "    if specialized_response:\n",
    "        state[\"response\"] = specialized_response\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"multi_agent_results\": multi_agent_results,\n",
    "        \"metadata\": {\n",
    "            **state.get(\"metadata\", {}),\n",
    "            \"multi_agent_used\": agent_name is not None  #True if an agent name was provided\n",
    "        }\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a779112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONTEXT-AWARE RESPONSE NODE\n",
    "# ============================================================================\n",
    "def context_aware_response_node(state: EnhancedAgentState) -> EnhancedAgentState:\n",
    "    \"\"\"Generate response with conversation history awareness.\"\"\"\n",
    "    llm = ChatGroq(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        temperature=0.7,\n",
    "        groq_api_key=os.getenv(\"GROQ_API_KEY\", \"\")\n",
    "    )\n",
    "    \n",
    "    # Build conversation context\n",
    "    history = state.get(\"conversation_history\", [])\n",
    "    #Consider last 5 messages\n",
    "    history_text = \"\\n\".join([f\"{msg['role']}: {msg['content']}\" for msg in history[-5:]]) if history else \"No previous conversation\"\n",
    "    \n",
    "    # Get User Context\n",
    "    user_context = state.get(\"user_context\", {})\n",
    "    user_info = f\"User Preferences: {json.dumps(user_context)}\" if user_context else \"\"\n",
    "    \n",
    "    system_prompt = f\"\"\"You are a context-aware customer support agent.\n",
    "    \n",
    "    Previous conversation:\n",
    "    {history_text}\n",
    "    {user_info}\n",
    "    \n",
    "    Use the conversation history to provide personalized and contextual reponses.\"\"\"\n",
    "    \n",
    "    user_prompt = f\"\"\"Current query: {state['query']}\n",
    "    \n",
    "    Available information: {state['retrieved_data']}\n",
    "    \n",
    "    Provide a helpful, contextual response that considers the conversation history.\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=user_prompt)\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    return {\n",
    "        **state, \n",
    "        \"response\": response.content,\n",
    "        \"metadata\": {\n",
    "            **state.get(\"metadata\", {}),\n",
    "            \"context_aware\": True\n",
    "        }\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae4660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
