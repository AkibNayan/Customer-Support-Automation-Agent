{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e0733ff",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "AI Agent Automation with LangGraph - Complete Implementation\n",
    "Customer Support Automation System using Groq API\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed340778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "import operator\n",
    "from datetime import datetime\n",
    "import json\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b667bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f46ec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7586db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STATE DEFINITION\n",
    "# ============================================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    category: str\n",
    "    retrieved_data: str\n",
    "    response: str\n",
    "    quality_score: int\n",
    "    timestamp: str\n",
    "    metadata: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbde9894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "class Config:\n",
    "    \"\"\"Configuration for AI Agent System\"\"\"\n",
    "    GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "    MODEL_NAME = \"llama-3.3-70b-versatile\"\n",
    "    TEMPERATURE = 0.7\n",
    "    MAX_TOKENS = 1000\n",
    "    \n",
    "    #Knowledge Base Simulation\n",
    "    KNOWLEDGE_BASE = {\n",
    "        'ORDER_STATUS': {\n",
    "            \"data\": \"Order tracking system connected. Typical delivery: 3-5 business days.\",\n",
    "            \"context\": \"Customer inquiring about order status\"\n",
    "        },\n",
    "        'REFUND': {\n",
    "            \"data\": \"Refund policy: 30-day return window. Full refund with receipt. Processing time: 5-7 business days.\",\n",
    "            \"context\": \"Customer requesting refund information\"\n",
    "        },\n",
    "        'SHIPPING': {\n",
    "            \"data\": \"Shipping options: Standard (5-7 days, $5.99), Express (2-3 days, $12.99), Overnight ($24.99).\",\n",
    "            \"context\": \"Customer inquiring about shipping\"\n",
    "        },\n",
    "        'POLICY': {\n",
    "            \"data\": \"Return policy: 30 days, original condition. Warranty: 1 year manufacturer warranty on electronics.\",\n",
    "            \"context\": \"Customer asking about policies\"\n",
    "        },\n",
    "        'TECHNICAL_SUPPORT': {\n",
    "            \"data\": \"Technical support available 24/7. Common issues: password reset, account access, product setup.\",\n",
    "            \"context\": \"Customer needs technical assistance\"\n",
    "        },\n",
    "        'GENERAL': {\n",
    "            \"data\": \"General customer support. Business hours: Mon-Fri 9AM-6PM EST. Contact: support@company.com\",\n",
    "            \"context\": \"General inquiry\"\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2a0467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LLM INITIALIZATION\n",
    "# ============================================================================\n",
    "def initialize_llm():\n",
    "    \"\"\"Initialize the Groq LLM\"\"\"\n",
    "    try:\n",
    "        llm = ChatGroq(\n",
    "            model=Config.MODEL_NAME,\n",
    "            temperature=Config.TEMPERATURE,\n",
    "            max_tokens=Config.MAX_TOKENS,\n",
    "            groq_api_key=Config.GROQ_API_KEY\n",
    "        )\n",
    "        logger.info(\"LLM initialized successfully\")\n",
    "        return llm\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialized LLM: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c62d09ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# AGENT NODES\n",
    "# ============================================================================\n",
    "def classify_query_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Node 1: Classify the incoming query into categories\n",
    "    \"\"\"\n",
    "    logger.info(f\"Classifying query: {state['query']}\")\n",
    "    \n",
    "    try:\n",
    "        llm = initialize_llm()\n",
    "        \n",
    "        prompt = f\"\"\"Analyze this customer support query and classify it into ONE of this categories:\n",
    "        - ORDER_STATUS: Questions about order tracking, delivery status\n",
    "        - REFUND: Refund requests, return inquiries\n",
    "        - SHIPPING: Shipping methods, costs, delivery times\n",
    "        - POLICY: Return policies, warranties, terms\n",
    "        - TECHNICAL_SUPPORT: Technical issues, troubleshooting\n",
    "        - GENERAL: Everything else\n",
    "        \n",
    "        Query: {state['query']}\n",
    "        \n",
    "        Responde with ONLY the category name, nothing else.\"\"\"\n",
    "        \n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        response = llm.invoke(messages)\n",
    "        category = response.content.strip()\n",
    "        \n",
    "        logger.info(f\"Query classified as: {category}\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"category\": category,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"metadata\": {\n",
    "                \"node\": \"classifier\",\n",
    "                \"status\": \"completed\"\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in classify_query_node: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"category\": \"GENERAL\",\n",
    "            \"metadata\": {\n",
    "                \"node\": \"classifier\",\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "745b74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Node 2: Retrieve relevant data based on classification\n",
    "    \"\"\"\n",
    "    logger.info(f\"Retrieving data for category: {state['category']}\")\n",
    "    \n",
    "    try:\n",
    "        category = state.get('category', \"GENERAL\")\n",
    "        \n",
    "        # Retrieve from knowledge base\n",
    "        knowledge = Config.KNOWLEDGE_BASE.get(category, Config.KNOWLEDGE_BASE[\"GENERAL\"])\n",
    "        retrieved_data = knowledge[\"data\"]\n",
    "        \n",
    "        logger.info(f\"Data retrieved successfully for {category}\")\n",
    "        \n",
    "        # Return updated state\n",
    "        return {\n",
    "            **state, # Unpack the previous state\n",
    "            \"retrieved_data\": retrieved_data,\n",
    "            \"metadata\": {\n",
    "                **state.get(\"metadata\", {}),\n",
    "                \"retriever\": \"completed\",\n",
    "                \"data_source\": \"knowledge_base\"\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error retrieved_data_node: {e}\")\n",
    "        return {\n",
    "            **state, \n",
    "            \"retrieved_data\": \"Error retrieving data\",\n",
    "            \"metadata\": {\n",
    "                **state.get(\"metadata\", {}),\n",
    "                \"retriever\": \"error\"\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd119885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Node 3: Generate a helpful response using LLM\n",
    "    \"\"\"\n",
    "    logger.info(\"Generating response\")\n",
    "    \n",
    "    try:\n",
    "        llm = initialize_llm()\n",
    "        \n",
    "        system_prompt = \"\"\"You are a professional and friendly customer support agent. Your goal is to provide helpful, acurate and empathetic reponses to customer queries. Keep responses concise but complete. Be professional yet warm\"\"\"\n",
    "        \n",
    "        user_prompt = f\"\"\"Based on this information: {state['retrieved_data']}, Provide a helpful response to this customer query: {state['query']}. Make the response personal, professionl and actionable.\"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            SystemMessage(content=system_prompt),\n",
    "            HumanMessage(content=user_prompt)\n",
    "        ]\n",
    "        \n",
    "        response = llm.invoke(messages)\n",
    "        generated_response = response.content.strip()\n",
    "        \n",
    "        logger.info(f\"Response generated successfully\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"response\": generated_response,\n",
    "            \"metadata\": {\n",
    "                **state.get(\"metadata\", {}),\n",
    "                \"generator\": \"completed\"\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in generate_response_node: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"response\": \"I appologize, but I'm having trouble generating a response. Please try again.\",\n",
    "            \"metadata\": {\n",
    "                **state.get(\"metadata\", {}),\n",
    "                \"generator\": \"error\"\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "429b5971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_check_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Node 4: Check the quality of the generated response.\n",
    "    \"\"\"\n",
    "    logger.info(\"Performing quality check\")\n",
    "    \n",
    "    try:\n",
    "        llm = initialize_llm()\n",
    "        \n",
    "        prompt = f\"\"\"Evaluate this customer support response on a scale of 1-10:\n",
    "        \n",
    "        Original Query: {state['query']}\n",
    "        Response: {state['response']}\n",
    "        \n",
    "        Consider:\n",
    "        - Relevance to the query\n",
    "        - Helpfulness and completeness\n",
    "        - Professionalism and tone\n",
    "        - Clarity and conciseness\n",
    "        \n",
    "        Respond with ONLY a number from 1-10, nothing else\n",
    "        \"\"\"\n",
    "        \n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        response = llm.invoke(messages)\n",
    "        \n",
    "        try:\n",
    "            quality_score = int(response.content.strip())\n",
    "        except ValueError:\n",
    "            quality_score = 7 # Default score if parsing fails\n",
    "        \n",
    "        logging.info(f\"Quality score: {quality_score}/10\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"quality_score\": quality_score,\n",
    "            \"metadata\": {\n",
    "                **state.get(\"metadata\", {}),\n",
    "                \"quality_checker\": \"completed\",\n",
    "                \"final_status\": \"success\"\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in quality_check_node: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"quality_score\": 0,\n",
    "            \"metadata\": {\n",
    "                **state.get(\"metadata\", {}),\n",
    "                \"quality_checker\": \"error\",\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fec10cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_regenerate(state: AgentState) -> Literal[\"regenerate\", \"end\"]:\n",
    "    \"\"\"\n",
    "    Conditional Edge: Decide if response needs regeneration.\n",
    "    \"\"\"\n",
    "    quality_score = state.get(\"quality_score\", 0)\n",
    "    \n",
    "    # If quality score is too low, regenerate (max 1 retry to avoid loops)\n",
    "    retry_count = state.get(\"metadata\", {}).get(\"retry_count\", 0)\n",
    "    \n",
    "    if quality_score < 6 and retry_count < 1:\n",
    "        logger.info(f\"Quality score too low ({quality_score}/10), regenerating...\")\n",
    "        return \"regenerate\"\n",
    "    return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df0636cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GRAPH CONSTRUCTION\n",
    "# ============================================================================\n",
    "def create_agent_workflow():\n",
    "    \"\"\"\n",
    "    Create and compile the Langgraph workflow.\n",
    "    \"\"\"\n",
    "    logger.info(\"Creating agent workflow graph\")\n",
    "    \n",
    "    #Initialize the graph\n",
    "    workflow = StateGraph(AgentState)\n",
    "    \n",
    "    # Add Nodes\n",
    "    workflow.add_node(\"classifier\", classify_query_node)\n",
    "    workflow.add_node(\"retriever\", retrieve_data_node)\n",
    "    workflow.add_node(\"generator\", generate_response_node)\n",
    "    workflow.add_node(\"quality_checker\", quality_check_node)\n",
    "    \n",
    "    # Define the flow\n",
    "    workflow.set_entry_point(\"classifier\")\n",
    "    workflow.add_edge(\"classifier\", \"retriever\")\n",
    "    workflow.add_edge(\"retriever\", \"generator\")\n",
    "    workflow.add_edge(\"generator\", \"quality_checker\")\n",
    "    \n",
    "    # Conditional edge for regeneration\n",
    "    workflow.add_conditional_edges(\n",
    "        \"quality_checker\",\n",
    "        should_regenerate,\n",
    "        {\n",
    "            \"regenerate\": \"generator\",\n",
    "            \"end\": END\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    #Compile the graph\n",
    "    app = workflow.compile()\n",
    "    \n",
    "    logger.info(\"Workflow compiled successfully\")\n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd5e82f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "def run_agent(query: str):\n",
    "    \"\"\"\n",
    "    Run the agent workflow with a given query\n",
    "    \"\"\"\n",
    "    logger.info(f\"Starting agent workflow for query: {query}\")\n",
    "    \n",
    "    # Create the workflow\n",
    "    app = create_agent_workflow()\n",
    "    \n",
    "    initial_state = {\n",
    "        \"query\": query,\n",
    "        \"category\": \"\",\n",
    "        \"retrieved_data\": \"\",\n",
    "        \"response\": \"\",\n",
    "        \"quality_score\": 0,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"metadata\": {\n",
    "            \"retry_count\": 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Run the workflow\n",
    "    try:\n",
    "        final_state = app.invoke(initial_state)\n",
    "        logger.info(\"Workflow completed successfully\")\n",
    "        return final_state\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error running workflow: {e}\")\n",
    "        raise\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04f2ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(result: AgentState):\n",
    "    \"\"\"\n",
    "    Display the results in a formatted way.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"AI Agent Automation Results\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nOriginal Query: {result['query']}\")\n",
    "    print(f\"\\nCategory: {result['category']}\")\n",
    "    print(f\"\\nRetrieved Data: {result['retrieved_data']}\")\n",
    "    print(f\"\\nGenerated Response: {result['response']}/10\")\n",
    "    print(f\"\\nQuality Score: {result['quality_score']}\")\n",
    "    print(f\"\\nTimestamp: {result['timestamp']}\")\n",
    "    print(f\"\\nMetadata: {json.dumps(result.get(\"metadata\", {}), indent=2)}\")\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7ce4fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 11:17:04,272 - __main__ - INFO - Starting agent workflow for query: What's the status of my order #12345?\n",
      "2025-11-25 11:17:04,272 - __main__ - INFO - Creating agent workflow graph\n",
      "2025-11-25 11:17:04,287 - __main__ - INFO - Workflow compiled successfully\n",
      "2025-11-25 11:17:04,343 - __main__ - INFO - Classifying query: What's the status of my order #12345?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– AI Agent Automation with LangGraph\n",
      "Using Groq API with Llama 3.3 70B\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TEST CASE 1/5\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 11:17:05,180 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-25 11:17:06,097 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-25 11:17:06,112 - __main__ - INFO - Query classified as: ORDER_STATUS\n",
      "2025-11-25 11:17:06,112 - __main__ - INFO - Retrieving data for category: ORDER_STATUS\n",
      "2025-11-25 11:17:06,112 - __main__ - INFO - Data retrieved successfully for ORDER_STATUS\n",
      "2025-11-25 11:17:06,117 - __main__ - INFO - Generating response\n",
      "2025-11-25 11:17:06,710 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-25 11:17:07,276 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-25 11:17:07,281 - __main__ - INFO - Response generated successfully\n",
      "2025-11-25 11:17:07,281 - __main__ - INFO - Performing quality check\n",
      "2025-11-25 11:17:07,943 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-25 11:17:08,095 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-25 11:17:08,110 - root - INFO - Quality score: 9/10\n",
      "2025-11-25 11:17:08,111 - __main__ - INFO - Workflow completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AI Agent Automation Results\n",
      "================================================================================\n",
      "\n",
      "Original Query: What's the status of my order #12345?\n",
      "\n",
      "Category: ORDER_STATUS\n",
      "\n",
      "Retrieved Data: Order tracking system connected. Typical delivery: 3-5 business days.\n",
      "\n",
      "Generated Response: Hi there, thank you for reaching out about the status of your order #12345. I've checked on it for you, and our system shows that it's currently being processed for delivery. Since we've recently connected our order tracking system, you can expect to receive updates on the status of your order soon. Typically, our deliveries take 3-5 business days. If you'd like to track your order in real-time, I can provide you with tracking information as soon as it's available. Would you like me to send you an update with the tracking details as soon as possible?/10\n",
      "\n",
      "Quality Score: 9\n",
      "\n",
      "Timestamp: 2025-11-25T11:17:06.112142\n",
      "\n",
      "Metadata: {\n",
      "  \"node\": \"classifier\",\n",
      "  \"status\": \"completed\",\n",
      "  \"retriever\": \"completed\",\n",
      "  \"data_source\": \"knowledge_base\",\n",
      "  \"generator\": \"completed\",\n",
      "  \"quality_checker\": \"completed\",\n",
      "  \"final_status\": \"success\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 11:18:55,037 - __main__ - INFO - Starting agent workflow for query: I need to return a defective product and get a refund\n",
      "2025-11-25 11:18:55,037 - __main__ - INFO - Creating agent workflow graph\n",
      "2025-11-25 11:18:55,062 - __main__ - INFO - Workflow compiled successfully\n",
      "2025-11-25 11:18:55,062 - __main__ - INFO - Classifying query: I need to return a defective product and get a refund\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST CASE 2/5\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 11:18:55,654 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-25 11:18:55,823 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-25 11:18:55,823 - __main__ - INFO - Query classified as: REFUND\n",
      "2025-11-25 11:18:55,837 - __main__ - INFO - Retrieving data for category: REFUND\n",
      "2025-11-25 11:18:55,837 - __main__ - INFO - Data retrieved successfully for REFUND\n",
      "2025-11-25 11:18:55,837 - __main__ - INFO - Generating response\n",
      "2025-11-25 11:18:56,404 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-25 11:18:57,007 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-25 11:18:57,023 - __main__ - INFO - Response generated successfully\n",
      "2025-11-25 11:18:57,028 - __main__ - INFO - Performing quality check\n",
      "2025-11-25 11:18:57,625 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-25 11:18:57,790 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-25 11:18:57,793 - root - INFO - Quality score: 9/10\n",
      "2025-11-25 11:18:57,793 - __main__ - INFO - Workflow completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AI Agent Automation Results\n",
      "================================================================================\n",
      "\n",
      "Original Query: I need to return a defective product and get a refund\n",
      "\n",
      "Category: REFUND\n",
      "\n",
      "Retrieved Data: Refund policy: 30-day return window. Full refund with receipt. Processing time: 5-7 business days.\n",
      "\n",
      "Generated Response: I'm so sorry to hear that you received a defective product. I'm here to help you with the return and refund process. Since you're within our 30-day return window, you're eligible for a full refund. To initiate the process, could you please provide me with your receipt and a brief description of the issue with the product? I'll guide you through the next steps and ensure that your refund is processed as quickly as possible, which typically takes 5-7 business days. Your satisfaction is my top priority, and I'm committed to making this right for you./10\n",
      "\n",
      "Quality Score: 9\n",
      "\n",
      "Timestamp: 2025-11-25T11:18:55.837109\n",
      "\n",
      "Metadata: {\n",
      "  \"node\": \"classifier\",\n",
      "  \"status\": \"completed\",\n",
      "  \"retriever\": \"completed\",\n",
      "  \"data_source\": \"knowledge_base\",\n",
      "  \"generator\": \"completed\",\n",
      "  \"quality_checker\": \"completed\",\n",
      "  \"final_status\": \"success\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 11:19:10,914 - __main__ - INFO - Starting agent workflow for query: How long does standard shipping take?\n",
      "2025-11-25 11:19:10,914 - __main__ - INFO - Creating agent workflow graph\n",
      "2025-11-25 11:19:10,925 - __main__ - INFO - Workflow compiled successfully\n",
      "2025-11-25 11:19:10,930 - __main__ - INFO - Classifying query: How long does standard shipping take?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST CASE 3/5\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 11:19:11,536 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-25 11:19:11,703 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-25 11:19:11,710 - __main__ - INFO - Query classified as: SHIPPING\n",
      "2025-11-25 11:19:11,711 - __main__ - INFO - Retrieving data for category: SHIPPING\n",
      "2025-11-25 11:19:11,711 - __main__ - INFO - Data retrieved successfully for SHIPPING\n",
      "2025-11-25 11:19:11,716 - __main__ - INFO - Generating response\n",
      "2025-11-25 11:19:12,287 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-25 11:19:12,706 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-25 11:19:12,708 - __main__ - INFO - Response generated successfully\n",
      "2025-11-25 11:19:12,708 - __main__ - INFO - Performing quality check\n",
      "2025-11-25 11:19:13,359 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-25 11:19:13,505 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-25 11:19:13,519 - root - INFO - Quality score: 9/10\n",
      "2025-11-25 11:19:13,520 - __main__ - INFO - Workflow completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AI Agent Automation Results\n",
      "================================================================================\n",
      "\n",
      "Original Query: How long does standard shipping take?\n",
      "\n",
      "Category: SHIPPING\n",
      "\n",
      "Retrieved Data: Shipping options: Standard (5-7 days, $5.99), Express (2-3 days, $12.99), Overnight ($24.99).\n",
      "\n",
      "Generated Response: Hello, I'd be happy to help you with that. Our Standard shipping option typically takes 5-7 business days to arrive, and it's a great value at just $5.99. If you have any other questions or would like to explore our other shipping options, such as Express or Overnight, please don't hesitate to ask. Would you like me to assist you with placing an order or tracking an existing one?/10\n",
      "\n",
      "Quality Score: 9\n",
      "\n",
      "Timestamp: 2025-11-25T11:19:11.711802\n",
      "\n",
      "Metadata: {\n",
      "  \"node\": \"classifier\",\n",
      "  \"status\": \"completed\",\n",
      "  \"retriever\": \"completed\",\n",
      "  \"data_source\": \"knowledge_base\",\n",
      "  \"generator\": \"completed\",\n",
      "  \"quality_checker\": \"completed\",\n",
      "  \"final_status\": \"success\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 11:19:31,635 - __main__ - INFO - Starting agent workflow for query: What is your return policy?\n",
      "2025-11-25 11:19:31,635 - __main__ - INFO - Creating agent workflow graph\n",
      "2025-11-25 11:19:31,645 - __main__ - INFO - Workflow compiled successfully\n",
      "2025-11-25 11:19:31,650 - __main__ - INFO - Classifying query: What is your return policy?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST CASE 4/5\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 11:19:32,234 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-25 11:19:32,387 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-25 11:19:32,387 - __main__ - INFO - Query classified as: POLICY\n",
      "2025-11-25 11:19:32,387 - __main__ - INFO - Retrieving data for category: POLICY\n",
      "2025-11-25 11:19:32,387 - __main__ - INFO - Data retrieved successfully for POLICY\n",
      "2025-11-25 11:19:32,401 - __main__ - INFO - Generating response\n",
      "2025-11-25 11:19:33,003 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-25 11:19:33,471 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-25 11:19:33,483 - __main__ - INFO - Response generated successfully\n",
      "2025-11-25 11:19:33,487 - __main__ - INFO - Performing quality check\n",
      "2025-11-25 11:19:34,075 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-25 11:19:34,337 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-25 11:19:34,337 - root - INFO - Quality score: 9/10\n",
      "2025-11-25 11:19:34,350 - __main__ - INFO - Workflow completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AI Agent Automation Results\n",
      "================================================================================\n",
      "\n",
      "Original Query: What is your return policy?\n",
      "\n",
      "Category: POLICY\n",
      "\n",
      "Retrieved Data: Return policy: 30 days, original condition. Warranty: 1 year manufacturer warranty on electronics.\n",
      "\n",
      "Generated Response: I'd be happy to help you with our return policy. If for any reason you're not satisfied with your purchase, you can return it within 30 days of receipt. To be eligible for a return, the item must be in its original condition, with all original packaging and accessories included. If you'd like to initiate a return, please don't hesitate to reach out to me directly and I'll guide you through the process. Would you like me to provide more details or answer any specific questions you may have about returns?/10\n",
      "\n",
      "Quality Score: 9\n",
      "\n",
      "Timestamp: 2025-11-25T11:19:32.387191\n",
      "\n",
      "Metadata: {\n",
      "  \"node\": \"classifier\",\n",
      "  \"status\": \"completed\",\n",
      "  \"retriever\": \"completed\",\n",
      "  \"data_source\": \"knowledge_base\",\n",
      "  \"generator\": \"completed\",\n",
      "  \"quality_checker\": \"completed\",\n",
      "  \"final_status\": \"success\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 11:19:47,986 - __main__ - INFO - Starting agent workflow for query: I'm having trouble logging into my account\n",
      "2025-11-25 11:19:47,986 - __main__ - INFO - Creating agent workflow graph\n",
      "2025-11-25 11:19:48,018 - __main__ - INFO - Workflow compiled successfully\n",
      "2025-11-25 11:19:48,021 - __main__ - INFO - Classifying query: I'm having trouble logging into my account\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST CASE 5/5\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 11:19:48,633 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-25 11:19:48,800 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-25 11:19:48,803 - __main__ - INFO - Query classified as: TECHNICAL_SUPPORT\n",
      "2025-11-25 11:19:48,809 - __main__ - INFO - Retrieving data for category: TECHNICAL_SUPPORT\n",
      "2025-11-25 11:19:48,810 - __main__ - INFO - Data retrieved successfully for TECHNICAL_SUPPORT\n",
      "2025-11-25 11:19:48,812 - __main__ - INFO - Generating response\n",
      "2025-11-25 11:19:49,402 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-25 11:19:49,834 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-25 11:19:49,838 - __main__ - INFO - Response generated successfully\n",
      "2025-11-25 11:19:49,841 - __main__ - INFO - Performing quality check\n",
      "2025-11-25 11:19:50,416 - __main__ - INFO - LLM initialized successfully\n",
      "2025-11-25 11:19:50,600 - httpx - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-25 11:19:50,604 - root - INFO - Quality score: 9/10\n",
      "2025-11-25 11:19:50,605 - __main__ - INFO - Workflow completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AI Agent Automation Results\n",
      "================================================================================\n",
      "\n",
      "Original Query: I'm having trouble logging into my account\n",
      "\n",
      "Category: TECHNICAL_SUPPORT\n",
      "\n",
      "Retrieved Data: Technical support available 24/7. Common issues: password reset, account access, product setup.\n",
      "\n",
      "Generated Response: I'm so sorry to hear that you're having trouble logging into your account. I'm here to help you get back up and running as quickly as possible. Can you please try resetting your password by clicking on the \"Forgot Password\" link on the login page? If that doesn't work, I'd be happy to assist you with troubleshooting or provide additional support to regain access to your account. Would you like me to walk you through the process or would you prefer I take a closer look into the issue?/10\n",
      "\n",
      "Quality Score: 9\n",
      "\n",
      "Timestamp: 2025-11-25T11:19:48.803305\n",
      "\n",
      "Metadata: {\n",
      "  \"node\": \"classifier\",\n",
      "  \"status\": \"completed\",\n",
      "  \"retriever\": \"completed\",\n",
      "  \"data_source\": \"knowledge_base\",\n",
      "  \"generator\": \"completed\",\n",
      "  \"quality_checker\": \"completed\",\n",
      "  \"final_status\": \"success\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "ðŸŽ‰ All test cases completed!\n",
      "\n",
      "\n",
      " To use with your own queries, call: run_agent('your_query_here')\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXAMPLE USAGE\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Set your Groq API key\n",
    "    # os.environ[\"GROQ_API_KEY\"] = \"your_api_key_here\"\n",
    "    \n",
    "    # Check if API key is set\n",
    "    if not Config.GROQ_API_KEY:\n",
    "        print(\"âŒ Error: GROQ_API_KEY not set!\")\n",
    "        print(\"Please set your Groq API key:\")\n",
    "        print(\"export GROQ_API_KEY='your_api_key_here'\")\n",
    "        exit(1)\n",
    "        \n",
    "    # Example queries to test\n",
    "    test_queries = [\n",
    "        \"What's the status of my order #12345?\",\n",
    "        \"I need to return a defective product and get a refund\",\n",
    "        \"How long does standard shipping take?\",\n",
    "        \"What is your return policy?\",\n",
    "        \"I'm having trouble logging into my account\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nðŸ¤– AI Agent Automation with LangGraph\")\n",
    "    print(\"Using Groq API with Llama 3.3 70B\\n\")\n",
    "    \n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"TEST CASE {i}/{len(test_queries)}\")\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        \n",
    "        try:\n",
    "            result = run_agent(query)\n",
    "            display_results(result)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing query: {e}\")\n",
    "        \n",
    "        if i < len(test_queries):\n",
    "            input(\"\\nPress Enter to continue to the next test case...\")\n",
    "            \n",
    "    print(\"\\nðŸŽ‰ All test cases completed!\\n\")\n",
    "    print(\"\\n To use with your own queries, call: run_agent('your_query_here')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaefe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
